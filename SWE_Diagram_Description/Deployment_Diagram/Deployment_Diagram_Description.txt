Dinner Service System 배치 다이어그램 설명

================================================================================

Dinner Service 시스템은 일곱 개의 노드에 분산되어 배포된다.
    Client Browser 노드
    Frontend Container 노드
    Backend Container 노드
    Database Container 노드
    Reverse Proxy Container 노드
    AI Server Container 노드
    Redis Container 노드


배치 다이어그램 구성 요소

배치 다이어그램은 컴포넌트, 아티팩트, 노드, 세 가지 주요 요소로 구성된다.

컴포넌트는 Component View에서 정의된 논리적 소프트웨어 단위이다. 시스템의 기능적 모듈을 나타내며 실행 시점에 노드에 배포된다. Dinner Service 시스템은 11개의 컴포넌트로 구성된다.

아티팩트는 물리적 구현 단위로 실행 파일, 라이브러리, 설정 파일, 데이터 파일을 포함한다. 컴포넌트를 실제로 구현하는 파일들이며 노드에 설치된다. Dinner Service 시스템은 8개의 아티팩트를 사용한다.

노드는 소프트웨어가 실행되는 물리적 또는 논리적 컴퓨팅 자원이다. 서버, 컨테이너, 클라이언트 디바이스, 외부 서비스를 포함하며 컴포넌트와 아티팩트를 호스팅한다.


Client Browser 노드

Customer Web App, Admin & Staff Web App, Common Components 컴포넌트를 배포한다.

Customer Web App 컴포넌트는 Component View에서 정의된 고객용 웹 애플리케이션이다. 주문, 메뉴 조회, 음성 주문, 결제 기능을 제공하는 클라이언트 프로그램으로 브라우저에서 JavaScript로 실행된다.

Admin & Staff Web App 컴포넌트는 Component View에서 정의된 관리자 및 직원용 웹 애플리케이션이다. 대시보드, 주문 관리, 메뉴 관리 기능을 제공하는 클라이언트 프로그램으로 역할별로 다른 화면을 표시한다.

Common Components 컴포넌트는 Component View에서 정의된 전역 공통 UI 컴포넌트이다. Header, Footer, UserDropdown 등을 제공하며 모든 페이지에서 재사용된다.


Frontend Container 노드 (dinner_service-frontend)

Frontend Container 노드는 Docker 컨테이너로 Next.js 애플리케이션을 실행한다.

next-app.js 아티팩트를 설치한다. Next.js Server로 React 컴포넌트를 서버에서 렌더링하고 HTML을 생성하는 실행 파일이다. 포트 3000에서 실행되며 Frontend Container를 구현한다.

build/ 아티팩트를 설치한다. 빌드된 정적 자산으로 HTML, CSS, JavaScript, 이미지 파일을 포함하는 디렉토리이다. 클라이언트 브라우저로 전송되며 Frontend Container를 구현한다.


Backend Container 노드 (dinner_service-backend)

API Routers, Domain Services, Integration & Realtime, Persistence 컴포넌트를 배포한다.

API Routers 컴포넌트는 Component View에서 정의된 HTTP 요청 라우팅 및 WebSocket 연결 관리 계층이다. 14개의 Router가 클라이언트 요청을 받아 Domain Services로 위임하는 Presentation Layer 프로그램이다.

Domain Services 컴포넌트는 Component View에서 정의된 비즈니스 로직 캡슐화 계층이다. 10개의 Service가 도메인 규칙을 적용하고 비즈니스 기능을 제공하는 Service Layer 프로그램이다.

Integration & Realtime 컴포넌트는 Component View에서 정의된 AI Server 통신 및 실시간 WebSocket 알림 계층이다. 3개의 Adapter가 Redis를 통해 AI Server와 통신하고 내부 도메인 모델로 변환하는 Adapter Layer 프로그램이다.

Persistence 컴포넌트는 Component View에서 정의된 데이터베이스 연결 및 트랜잭션 관리 계층이다. Database, SessionLocal, Engine 모듈이 SQLAlchemy ORM으로 데이터베이스 작업을 추상화하는 Data Access Layer 프로그램이다.

main.py 아티팩트를 설치한다. FastAPI 애플리케이션 진입점으로 모든 컴포넌트를 초기화하고 라우터를 등록하는 실행 파일이다. Backend Container를 구현한다.

uvicorn 아티팩트를 설치한다. ASGI 서버로 FastAPI 애플리케이션을 실행하는 실행 파일이다. 포트 8000에서 실행되며 Backend Container를 구현한다.


Database Container 노드 (dinner_service_db)

Database Container 노드는 Docker 컨테이너로 PostgreSQL 데이터베이스를 실행한다.

postgres 아티팩트를 설치한다. PostgreSQL 17 데이터베이스 서버로 SQL 쿼리를 처리하고 트랜잭션을 관리하는 실행 파일이다. 포트 5432에서 실행되며 Database Container를 구현한다.

pgdata/ 아티팩트를 설치한다. 데이터베이스 파일들이 저장되는 영구 볼륨 디렉토리이다. 주문, 사용자, 메뉴, 재고 등 모든 애플리케이션 데이터가 저장되며 Database Container를 구현한다.


Reverse Proxy Container 노드 (dinner_service_caddy)

Reverse Proxy Container 노드는 Docker 컨테이너로 Caddy 리버스 프록시를 실행한다.

caddy 아티팩트를 설치한다. HTTP/HTTPS 리버스 프록시로 SSL 종료 및 라우팅을 담당하는 실행 파일이다. 포트 80(HTTP)과 443(HTTPS)에서 실행되며 클라이언트 요청을 Frontend Container와 Backend Container로 분배한다. Reverse Proxy Container를 구현한다.

Caddyfile 아티팩트를 설치한다. 라우팅 규칙과 TLS 설정을 정의하는 설정 파일이다. /customer, /admin 경로는 Frontend Container로, /api/*, /ws/* 경로는 Backend Container로 라우팅하며 Reverse Proxy Container를 구현한다.


AI Server Container 노드 (dinner_service-ai-server)

AI Server Container 노드는 Docker 컨테이너로 오픈소스 AI 모델을 실행하는 독립 워커 서비스이다.

FastAPI 기반 Worker 프로세스를 실행하며, Redis 큐를 모니터링하고 AI 작업을 처리한다. 포트 8001을 노출하며, Health Check 엔드포인트를 제공한다.

구성 요소로는 AIWorker, Whisper STT Service, Qwen LLM Service, Stable Diffusion Image Service가 있다. AIWorker는 Redis 큐 모니터링 및 작업 분배 프로세스이다. Whisper STT Service는 음성을 텍스트로 변환하며 openai/whisper-large-v3 모델을 사용한다. Qwen LLM Service는 자연어 이해 및 대화 분석을 수행하며 Qwen/Qwen3-4B-Instruct-2507 모델을 vLLM 최적화로 실행한다. Stable Diffusion Image Service는 케이크 이미지를 생성하며 stabilityai/stable-diffusion-3.5-medium 모델을 사용한다.

환경 변수로는 REDIS_HOST(기본값: redis), REDIS_PORT(기본값: 6379), MODEL_CACHE_DIR(기본값: /app/models), GPU_MEMORY_UTILIZATION(기본값: 0.9), WORKER_CONCURRENCY(기본값: 3)가 있다.

리소스 요구사항으로는 CPU 4 cores 이상 권장, Memory 16GB 이상 권장, GPU NVIDIA GPU (CUDA 11.8+) 권장 (CPU 모드도 지원), Disk 20GB 이상 (AI 모델 저장용)이 필요하다.

의존성으로는 Redis Container와 연결되어 큐 및 pub/sub 통신을 수행한다.


Redis Container 노드 (dinner_service-redis)

Redis Container 노드는 Docker 컨테이너로 Backend와 AI Server 간의 메시지 큐 및 pub/sub 통신을 담당하는 인메모리 데이터베이스이다.

Redis 7.x 버전을 사용하며, 포트 6379를 노출한다.

구성 요소로는 ai:queue:stt, ai:queue:llm, ai:queue:image, ai:result:* 채널이 있다. ai:queue:stt는 STT 작업 요청 큐이고, ai:queue:llm은 LLM 분석 작업 요청 큐이며, ai:queue:image는 이미지 생성 작업 요청 큐이다. ai:result:* 채널은 작업 결과 pub/sub 채널이다.

환경 변수로는 REDIS_PASSWORD(옵션), REDIS_MAXMEMORY(기본값: 2GB), REDIS_MAXMEMORY_POLICY(기본값: allkeys-lru)가 있다.

리소스 요구사항으로는 Memory 2GB 이상 권장, Persistence AOF (Append Only File) 활성화가 필요하다.


물리적 연결 및 통신 경로

Client Browser와 Reverse Proxy Container는 HTTP/HTTPS 프로토콜로 연결된다. 포트 80과 443을 사용하여 통신하며 클라이언트의 모든 요청이 이 경로를 통해 전달된다.

Reverse Proxy Container와 Frontend Container는 HTTP 프로토콜로 연결된다. 포트 3000을 사용하여 통신하며 /customer, /admin 경로 요청이 이 경로를 통해 전달된다.

Reverse Proxy Container와 Backend Container는 HTTP 프로토콜로 연결된다. 포트 8000을 사용하여 통신하며 /api/*, /ws/* 경로 요청이 이 경로를 통해 전달된다.

Backend Container와 Database Container는 TCP 프로토콜로 연결된다. 포트 5432를 사용하여 통신하며 PostgreSQL Wire Protocol로 데이터베이스 쿼리가 전송된다.

Backend Container와 Redis Container는 TCP 프로토콜로 연결된다. 포트 6379를 사용하여 통신하며 RESP (Redis Serialization Protocol)를 사용한다. Backend의 AIClient는 Redis 큐(ai:queue:stt, ai:queue:llm, ai:queue:image)에 작업 요청을 전송하고, ai:result:{request_id} 채널을 구독하여 결과를 수신한다.

Redis Container와 AI Server Container는 TCP 프로토콜로 연결된다. 포트 6379를 사용하여 통신하며 RESP (Redis Serialization Protocol)를 사용한다. AI Server의 Worker는 Redis 큐를 polling 방식으로 모니터링하고, brpop 명령을 사용하여 블로킹 방식으로 작업을 가져온다. 작업 처리 후 결과를 ai:result:{request_id} 채널에 발행하고, publish 명령을 사용하여 pub/sub 패턴으로 결과를 전송한다.


배포 관계와 구현 관계

배포 관계는 컴포넌트가 노드에 배포되는 관계를 나타낸다. <<deploy>> 스테레오타입으로 표시되며 논리적 소프트웨어 단위가 물리적 실행 환경에 설치됨을 의미한다. Customer Web App, Admin & Staff Web App, Common Components 컴포넌트는 Client Browser 노드에 배포되고, API Routers, Domain Services, Integration & Realtime, Persistence 컴포넌트는 Backend Container 노드에 배포된다. AIWorker, Whisper STT Service, Qwen LLM Service, Stable Diffusion Image Service 컴포넌트는 AI Server Container 노드에 배포된다.

구현 관계는 아티팩트가 노드를 구현하는 관계를 나타낸다. <<implementation>> 스테레오타입으로 표시되며 물리적 파일이 실행 환경을 실제로 구성함을 의미한다. next-app.js, build/ 아티팩트는 Frontend Container 노드를 구현하고, main.py, uvicorn 아티팩트는 Backend Container 노드를 구현한다. postgres, pgdata/ 아티팩트는 Database Container 노드를 구현하며, caddy, Caddyfile 아티팩트는 Reverse Proxy Container 노드를 구현한다.


================================================================================

이상으로 Dinner Service 시스템의 배치 다이어그램 구성에 대한 설명을 마친다.
